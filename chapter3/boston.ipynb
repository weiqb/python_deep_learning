{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "# 波士顿房价预测:回归\n",
    "\n",
    "# numpy 1.17 版本与keras兼容有问题,需要设置 allow_pickle = True\n",
    "import numpy as np\n",
    "old = np.load\n",
    "np.load = lambda *a,**k: old(*a,**k,allow_pickle=True)\n",
    "\n",
    "from keras.datasets import boston_housing\n",
    "# 加载数据\n",
    "# 设置 path 以便使用本地文件\n",
    "# targets中为房价\n",
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data(path = \"boston_housing.npz\")\n",
    "\n",
    "# 还原 numpy 设置\n",
    "np.load = old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据标准化\n",
    "mean = train_data.mean(axis = 0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis = 0)\n",
    "train_data /= std\n",
    "\n",
    "test_data -= mean\n",
    "test_data /= std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建网络\n",
    "#from keras import models\n",
    "#from keras import layers\n",
    "# tensorflow 2.0 版本,需要如下写法\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_model():\n",
    "    # 层设置\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation = 'relu', input_shape = (train_data.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation = 'relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    # 编译模型\n",
    "    # 也可以使用类方式\n",
    "    model.compile(optimizer = 'rmsprop', loss = 'mse', metrics = ['mae'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "processing fold # 0\n0\n"
    }
   ],
   "source": [
    "# k折交叉验证:数据集较少,充分发挥数据潜力\n",
    "import numpy as np\n",
    "\n",
    "k = 4\n",
    "num_val_samples = len(train_data) \n",
    "num_epochs = 100\n",
    "all_scores = []\n",
    "\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "    partial_train_data = np.concatenate( # 准备训练数据：其他所有分区的数据\n",
    "        [train_data[:i * num_val_samples],\n",
    "         train_data[(i + 1) * num_val_samples:]],\n",
    "         axis = 0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [train_targets[:i * num_val_samples],\n",
    "         train_targets[(i + 1) * num_val_samples:]],\n",
    "         axis = 0)\n",
    "    \n",
    "    print(len(partial_train_data))\n",
    "    model = build_model()\n",
    "    history = model.fit(partial_train_data, partial_train_targets,\n",
    "              epochs = num_epochs, batch_size = 1, verbose = 0)\n",
    "    print(history.history)\n",
    "    val_mse, val_mae = model.evalute(val_data, val_targets, verbose = 0)\n",
    "    all_scores.append(val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k折交叉验证:数据集较少,充分发挥数据潜力\n",
    "# 保存每折的验证结果\n",
    "import numpy as np\n",
    "\n",
    "k = 4\n",
    "num_val_samples = len(train_data) \n",
    "num_epochs = 100\n",
    "all_scores = []\n",
    "all_mae_histories = []\n",
    "\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "    partial_train_data = np.concatenate( # 准备训练数据：其他所有分区的数据\n",
    "        [train_data[:i * num_val_samples],\n",
    "         train_data[(i + 1) * num_val_samples:]],\n",
    "         axis = 0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [train_targets[:i * num_val_samples],\n",
    "         train_targets[(i + 1) * num_val_samples:]],\n",
    "         axis = 0)\n",
    "    \n",
    "    model = build_model()\n",
    "    history = model.fit(partial_train_data, partial_train_targets,\n",
    "              epochs = num_epochs, batch_size = 1, verbose = 0)\n",
    "    mae_history = history.history['val_mean_absolute_error']\n",
    "    all_mae_histories.append(mae_history)\n",
    "\n",
    "# 计算 mae 均值\n",
    "average_mae_history = [\n",
    "    np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制验证分数\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\n",
    "plt.xlabel('Epoches')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()\n"
   ]
  }
 ]
}